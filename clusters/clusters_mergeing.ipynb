{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-13T14:14:35.861360Z",
     "start_time": "2025-06-13T14:14:35.856360Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:21:02.965557Z",
     "start_time": "2025-06-13T14:21:02.874139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_m_0 = \"min_0\"\n",
    "df_m_1 = \"min_1\"\n",
    "df_m_2 = 'min_2'\n",
    "# df_m_3 = pd.read_csv('../dataset/min_3.csv')\n",
    "df_0 = 'informative_cluster_0'\n",
    "df_1 = 'informative_cluster_1'\n",
    "# df_2 = pd.read_csv('../dataset/informative_cluster_2.csv')\n",
    "selected_file = df_m_0\n",
    "files = [df_m_0, df_m_1, df_m_2, df_0, df_1]\n",
    "df= pd.read_csv(\"../dataset/\" + selected_file + \".csv\")\n"
   ],
   "id": "6d9f233078554271",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:22:45.714282Z",
     "start_time": "2025-06-13T14:22:45.645884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# List of filenames\n",
    "files = [df_m_0, df_m_1, df_m_2]\n",
    "output_name = \"df_min\"\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"../dataset/\"+file+\".csv\").drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")  # optional drop\n",
    "    df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.to_csv(\"../dataset/\"+output_name + \".csv\")\n"
   ],
   "id": "c39642e67e4914af",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:23:13.448207Z",
     "start_time": "2025-06-13T14:23:13.393219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# List of filenames\n",
    "files = [df_0, df_1]\n",
    "output_name = \"df_majority\"\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(\"../dataset/\"+file+\".csv\").drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")  # optional drop\n",
    "    df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.to_csv(\"../dataset/\"+output_name + \".csv\")\n"
   ],
   "id": "b8efff7895133c19",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Merge 2*3 clusters",
   "id": "9965654fa019f623"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T16:20:43.528172Z",
     "start_time": "2025-06-13T16:20:43.066793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Load your 5 cluster files\n",
    "minority_files = [df_m_0, df_m_1, df_m_2]\n",
    "majority_files = [df_0,df_1]\n",
    "\n",
    "# Read them into a dictionary\n",
    "cluster_dfs = {\n",
    "    fname: pd.read_csv(f\"../dataset/{fname}.csv\").drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "    for fname in minority_files + majority_files\n",
    "}\n",
    "# Store the combinations\n",
    "combined_groups = []\n",
    "\n",
    "# One-to-One combinations\n",
    "for min_file, maj_file in itertools.product(minority_files, majority_files):\n",
    "    combined_df = pd.concat([cluster_dfs[min_file], cluster_dfs[maj_file]], ignore_index=True)\n",
    "    combined_df.to_csv(f\"../dataset/{min_file}_{maj_file}.csv\")\n",
    "\n",
    "\n",
    "# Two-to-Two combinations\n",
    "for min_pair in itertools.combinations(minority_files, 2):\n",
    "    for maj_pair in itertools.combinations(majority_files, 2):\n",
    "        # Combine DataFrames\n",
    "        dfs_to_merge = [cluster_dfs[f] for f in min_pair + maj_pair]\n",
    "        combined_df = pd.concat(dfs_to_merge, ignore_index=True)\n",
    "\n",
    "        # Create a descriptive filename\n",
    "        parts = [f.replace(\".csv\", \"\") for f in min_pair + maj_pair]\n",
    "        filename = f\"../dataset/{'_'.join(parts)}.csv\"\n",
    "        # print(filename)\n",
    "        # Save to CSV\n",
    "        combined_df.to_csv(filename, index=False)\n"
   ],
   "id": "3464dfb3a7d3ebd1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:02:29.173784Z",
     "start_time": "2025-06-13T15:02:29.170664Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e18823e30f2f2e03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a10471226f3004d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
